{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from llama_index.core import Settings, ServiceContext, StorageContext, SimpleDirectoryReader, PropertyGraphIndex\n",
    "from llama_index.llms.groq import Groq as Groq_llamaindex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.replicate import Replicate\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.graph_stores.neo4j import Neo4jGraphStore, Neo4jPropertyGraphStore\n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.agent import ReActAgent, FunctionCallingAgentWorker, AgentRunner\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "from milvus import default_server\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "BASE_ENTITY_LABEL = \"__Entity__\"\n",
    "BASE_NODE_LABEL = \"__Node__\"\n",
    "\n",
    "# Retrieve API keys and credentials securely\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_URL = os.getenv('NEO4J_URL', 'bolt://localhost:7687')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE', 'neo4j')\n",
    "REPLICATE_API_KEY = os.getenv('REPLICATE_API_KEY')\n",
    "os.environ[\"REPLICATE_API_KEY\"] = REPLICATE_API_KEY\n",
    "\n",
    "#Initialize the Replicate class\n",
    "llm = Replicate(\n",
    "    model=\"meta/meta-llama-3-70b-instruct\"\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "ServiceContext.llm = llm\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "property_graph_store = Neo4jPropertyGraphStore(\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    url=NEO4J_URL,\n",
    "    database=NEO4J_DATABASE,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(property_graph_store=property_graph_store)\n",
    "\n",
    "\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=property_graph_store,\n",
    "    llm=llm,\n",
    "    embed_model=Settings.embed_model,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummnQuery:\n",
    "    def __init__(self, query_str, embedding):\n",
    "        self.query_str = query_str\n",
    "        self.filters = None\n",
    "        self.query_embedding = embedding\n",
    "        self.similarity_top_k = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load questions sp_cot_data/pseudo_dataset_completion.json\n",
    "import json\n",
    "with open('transport_data/sp_cot/pseudo_dataset_completion.json') as f:\n",
    "    data = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = data.keys()\n",
    "questions = []\n",
    "answers = []\n",
    "for type in types:\n",
    "    for entry in data[type]:\n",
    "        questions.append(entry['question'])\n",
    "        answers.append(entry['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_depth in range(1, 7):\n",
    "    similarity_top_k = 4    \n",
    "    path_depth = current_depth\n",
    "    vector_retriever = VectorContextRetriever(\n",
    "    index.property_graph_store,\n",
    "    # only needed when the graph store doesn't support vector queries\n",
    "    # vector_store=index.vector_store,\n",
    "    embed_model=Settings.embed_model,\n",
    "    # include source chunk text with retrieved paths\n",
    "    include_text=True,\n",
    "    # the number of nodes to fetch\n",
    "    similarity_top_k=similarity_top_k,\n",
    "    # the depth of relations to follow after node retrieval\n",
    "    path_depth=path_depth,\n",
    "    \n",
    "  \n",
    "    )\n",
    "\n",
    "    #retriever = index.as_retriever(sub_retrievers=[vector_retriever])\n",
    "    index_query_engine = index.as_query_engine(sub_retrievers=[vector_retriever])\n",
    "    index_retriever = index.as_retriever(sub_retrievers=[vector_retriever])\n",
    "\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    for  i, question in enumerate(questions):\n",
    "        \n",
    "\n",
    "       \n",
    "        query_str = question\n",
    "        print(query_str)\n",
    "        embedding = index_retriever.sub_retrievers[0]._embed_model.get_agg_embedding_from_queries([query_str])\n",
    "        query = DummnQuery(query_str, embedding)\n",
    "\n",
    "    \n",
    "        print(query.query_str)\n",
    "        nodes_with_score = property_graph_store.vector_query(query)\n",
    "        ids = []\n",
    "        for node in nodes_with_score[0]:\n",
    "            ids.append(node.name)\n",
    "     \n",
    "\n",
    "        response_unsorted = property_graph_store.structured_query(\n",
    "        f\"\"\"\n",
    "        WITH $ids AS id_list\n",
    "        UNWIND range(0, size(id_list) - 1) AS idx\n",
    "        MATCH (e:`{BASE_ENTITY_LABEL}`)\n",
    "        WHERE e.id = id_list[idx]\n",
    "        MATCH p=(e)-[r*1..{path_depth}]-(other)\n",
    "        WHERE ALL(rel IN relationships(p) WHERE type(rel) <> 'MENTIONS')\n",
    "        UNWIND relationships(p) AS rel\n",
    "        WITH DISTINCT rel, idx, id_list[idx] AS seed_id, vector.similarity.cosine(rel.embedding, $embedding) AS rel_score\n",
    "        WITH startNode(rel) AS source,\n",
    "            type(rel) AS type,\n",
    "            rel{{.*}} AS rel_properties,\n",
    "            endNode(rel) AS endNode,\n",
    "            idx,\n",
    "            rel_score,\n",
    "            seed_id\n",
    "        LIMIT toInteger($limit)\n",
    "        RETURN source.id AS source_id, \n",
    "            [l IN labels(source) WHERE NOT l IN ['{BASE_ENTITY_LABEL}', '{BASE_NODE_LABEL}'] | l][0] AS source_type,\n",
    "            source{{.*, embedding: Null, id: Null}} AS source_properties,\n",
    "            type,\n",
    "            rel_properties,\n",
    "            endNode.id AS target_id, \n",
    "            [l IN labels(endNode) WHERE NOT l IN ['{BASE_ENTITY_LABEL}', '{BASE_NODE_LABEL}'] | l][0] AS target_type,\n",
    "            endNode{{.*, embedding: Null, id: Null}} AS target_properties,\n",
    "            idx,\n",
    "            rel_score,\n",
    "            seed_id\n",
    "        ORDER BY idx\n",
    "        LIMIT toInteger($limit)\n",
    "        \"\"\",\n",
    "        param_map={\"ids\": ids, \"limit\": 30, \"embedding\": query.query_embedding},\n",
    "    )\n",
    "        \n",
    "        response_sorted = property_graph_store.structured_query(f\"\"\"\n",
    "        // Assign an index to each id in the original list\n",
    "        WITH [i IN RANGE(0, size($ids)-1) | {{id: $ids[i], seed_idx: i}}] AS id_list\n",
    "        UNWIND id_list AS id_map\n",
    "        MATCH (e:`{BASE_ENTITY_LABEL}`)\n",
    "        WHERE e.id = id_map.id\n",
    "        WITH e, id_map.id AS id, id_map.seed_idx AS seed_idx  // Include seed_idx\n",
    "\n",
    "        // For each id, find the top N most relevant relations\n",
    "        CALL {{\n",
    "            WITH e\n",
    "            MATCH p=(e)-[r*1..{path_depth}]-(other)\n",
    "            WHERE ALL(rel IN relationships(p) WHERE type(rel) <> 'MENTIONS')\n",
    "            UNWIND relationships(p) AS rel\n",
    "            WITH DISTINCT rel\n",
    "            WHERE rel.embedding IS NOT NULL AND size(rel.embedding) = $dimension\n",
    "            WITH rel, vector.similarity.cosine(rel.embedding, $embedding) AS rel_score\n",
    "            ORDER BY rel_score DESC\n",
    "            LIMIT toInteger(7)\n",
    "            RETURN rel, rel_score\n",
    "        }}\n",
    "\n",
    "        WITH DISTINCT rel, rel_score, id AS seed_id, seed_idx  // Include seed_idx\n",
    "        WITH startNode(rel) AS source,\n",
    "            type(rel) AS type,\n",
    "            rel{{.*}} AS rel_properties,\n",
    "            endNode(rel) AS endNode,\n",
    "            seed_id,\n",
    "            seed_idx,  // Include seed_idx\n",
    "            rel_score\n",
    "\n",
    "        // Find the best matching text node for the source node\n",
    "        CALL {{\n",
    "            WITH source\n",
    "            OPTIONAL MATCH (source)-[:MENTIONS]-(text_source)\n",
    "            WHERE text_source.embedding IS NOT NULL AND size(text_source.embedding) = $dimension\n",
    "            WITH text_source, vector.similarity.cosine(text_source.embedding, $embedding) AS source_score\n",
    "            ORDER BY source_score DESC\n",
    "            LIMIT 1\n",
    "            RETURN text_source.id AS source_best_text_id, source_score AS source_best_score\n",
    "        }}\n",
    "\n",
    "        // Find the best matching text node for the end node\n",
    "        CALL {{\n",
    "            WITH endNode\n",
    "            OPTIONAL MATCH (endNode)-[:MENTIONS]-(text_target)\n",
    "            WHERE text_target.embedding IS NOT NULL AND size(text_target.embedding) = $dimension\n",
    "            WITH text_target, vector.similarity.cosine(text_target.embedding, $embedding) AS target_score\n",
    "            ORDER BY target_score DESC\n",
    "            LIMIT 1\n",
    "            RETURN text_target.id AS target_best_text_id, target_score AS target_best_score\n",
    "        }}\n",
    "\n",
    "        RETURN DISTINCT \n",
    "            source.id AS source_id,\n",
    "            [l IN labels(source) WHERE NOT l IN ['{BASE_ENTITY_LABEL}', '{BASE_NODE_LABEL}'] | l][0] AS source_type,\n",
    "            source{{.*, embedding: NULL, id: NULL, best_text_id: source_best_text_id, best_text_score: source_best_score }} AS source_properties,\n",
    "            type,\n",
    "            rel_properties,\n",
    "            endNode.id AS target_id,\n",
    "            [l IN labels(endNode) WHERE NOT l IN ['{BASE_ENTITY_LABEL}', '{BASE_NODE_LABEL}'] | l][0] AS target_type,\n",
    "            endNode{{.*, embedding: NULL, id: NULL, best_text_id: target_best_text_id, best_text_score: target_best_score }} AS target_properties,\n",
    "            rel_score,\n",
    "            seed_id,\n",
    "            seed_idx  // Include seed_idx\n",
    "\n",
    "        ORDER BY seed_idx, rel_score DESC  // Order by seed_idx to maintain initial order\n",
    "        \"\"\",\n",
    "        param_map={\n",
    "            \"ids\": ids,\n",
    "            \"limit\": 30,\n",
    "            \"embedding\": query.query_embedding,\n",
    "            \"dimension\": len(query.query_embedding),\n",
    "        },\n",
    "    )      \n",
    "\n",
    "        extracted_response_unsorted = []\n",
    "        for record in response_unsorted:\n",
    "            extracted_response_unsorted.append({\n",
    "                \"seed_id\": record[\"seed_id\"],\n",
    "                \"source_id\": record[\"source_id\"],\n",
    "                \"type\": record[\"type\"],\n",
    "                \"target_id\": record[\"target_id\"],\n",
    "                \"rel_score\": record[\"rel_score\"]\n",
    "            })\n",
    "        \n",
    "        extracted_response_sorted = []\n",
    "        for record in response_sorted:\n",
    "            extracted_response_sorted.append({\n",
    "                \"seed_id\": record[\"seed_id\"],\n",
    "                \"source_id\": record[\"source_id\"],\n",
    "                \"type\": record[\"type\"],\n",
    "                \"target_id\": record[\"target_id\"],\n",
    "                \"rel_score\": record[\"rel_score\"]\n",
    "            })\n",
    "        print(extracted_response_unsorted)\n",
    "        # if directory does not exist make it\n",
    "        if not os.path.exists(f\"OIA Nodes/full_unsorted_k4_d{path_depth}\"):\n",
    "            os.makedirs(f\"OIA Nodes/full_unsorted_k4_d{path_depth}\")\n",
    "        with open(f\"OIA Nodes/full_unsorted_k4_d{path_depth}/{i+1}.txt\", 'w') as f:\n",
    "            f.write(f\"{query.query_str}\\n\")\n",
    "            # do not print the keys of the dictionary just the values with a  head --[relation]--> tail\n",
    "            # add the ids to know which ones are the seeds\n",
    "            for id in ids:\n",
    "                f.write(f\"Seed: {id}\\n\")\n",
    "\n",
    "            for item in extracted_response_unsorted:\n",
    "                    f.write(f\"[{item['seed_id']}]: {item['source_id']} --[{item['type']}]-> {item['target_id']} {item['rel_score']}\\n\")\n",
    "        \n",
    "        # the same for the sorted\n",
    "        if not os.path.exists(f\"OIA Nodes/full_sorted_k4_d{path_depth}\"):\n",
    "            os.makedirs(f\"OIA Nodes/full_sorted_k4_d{path_depth}\")\n",
    "        with open(f\"OIA Nodes/full_sorted_k4_d{path_depth}/{i+1}.txt\", 'w') as f:\n",
    "            f.write(f\"{query.query_str}\\n\")\n",
    "            # do not print the keys of the dictionary just the values with a  head --[relation]--> tail\n",
    "            # add the ids to know which ones are the seeds\n",
    "            for id in ids:\n",
    "                f.write(f\"Seed: {id}\\n\")\n",
    "\n",
    "            for item in extracted_response_sorted:\n",
    "                    f.write(f\"[{item['seed_id']}]: {item['source_id']} --[{item['type']}]-> {item['target_id']} {item['rel_score']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nzta_experiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
